{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to Neural Networks and Deep Learning_R7_INN_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGPO6KadVTBC"
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1qdwJtM2u6d"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHc7uQZR3B8n"
      },
      "source": [
        "##Read the data from the h5py file and understand the train/test splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObFk_jx6Va4z",
        "outputId": "b860264c-0d57-4ab4-e3da-87456fbf12c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import h5py\n",
        "h5f=h5py.File('/content/drive/My Drive/SVHN_single_grey1.h5','r')\n",
        "h5f.keys()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSD35JwzVssV"
      },
      "source": [
        "# Load the traning , test and validation set\n",
        "X_train = h5f['X_train'][:]\n",
        "y_train = h5f['y_train'][:]\n",
        "X_test = h5f['X_test'][:]\n",
        "y_test = h5f['y_test'][:]\n",
        "X_val=h5f['X_val'][:]\n",
        "y_val=h5f['y_val'][:]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1bH_6-lTvoB",
        "outputId": "92e6e575-3f3b-4ba2-a9df-ae901c0fa6f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape,y_train.shape,X_test.shape,y_test.shape,X_val.shape,y_val.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((42000, 32, 32),\n",
              " (42000,),\n",
              " (18000, 32, 32),\n",
              " (18000,),\n",
              " (60000, 32, 32),\n",
              " (60000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXYVTZyVUZrG",
        "outputId": "e1f52074-44bf-4891-d9f1-d59c28776720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Total Records',y_train.size+y_test.size+y_val.size)\n",
        "total_records=y_train.size+y_test.size+y_val.size\n",
        "print('Train records percentage',y_train.size/total_records*100)\n",
        "print('Test records percentage',y_test.size/total_records*100)\n",
        "print('Validation records percentage',y_val.size/total_records*100)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Records 120000\n",
            "Train records percentage 35.0\n",
            "Test records percentage 15.0\n",
            "Validation records percentage 50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vav6n9UBW3kY"
      },
      "source": [
        "## One hot encode the labels for train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNb8UhUUW_3D"
      },
      "source": [
        "trainY = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "valY = tf.keras.utils.to_categorical(y_val, num_classes=10)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWvY4CL3XN_v",
        "outputId": "57dcc715-23d9-4c40-8af3-de3390097b35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "trainY[9]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHhZORFSVXLB",
        "outputId": "0ea09a02-3d49-45ce-ad87-68e195ab60b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X_train[9],cmap='gray')\n",
        "plt.show()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE6jPDUYVxUk",
        "outputId": "bf201a99-7bda-4910-af59-ccf66467957d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train[9]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noIO4dIb3Td3"
      },
      "source": [
        "## Reshape and normalize the train and test features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EUApabxgttE"
      },
      "source": [
        "trainX = X_train.astype('float32')\n",
        "valX=X_val.astype('float32')\n",
        "testX = X_test.astype('float32')\n",
        "trainX /= 255\n",
        "valX /= 255\n",
        "testX /= 255\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCeFeqt13oxt"
      },
      "source": [
        "## Define the model architecture using TensorFlow with a flatten layer followed by dense layers with activation as ReLu and softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBO_okDDV0Uw"
      },
      "source": [
        "\n",
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Reshape data from 2D to 1D -> 32x32 to 1024\n",
        "model.add(tf.keras.layers.Reshape((1024,),input_shape=(32,32,)))\n",
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tpOMbdFX5gQ"
      },
      "source": [
        "#Add 1st hidden layer\n",
        "model.add(tf.keras.layers.Dense(750, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxJ3kj98X-0S"
      },
      "source": [
        "#Add 2nd hidden layer\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEWPqUmwlVw5"
      },
      "source": [
        "#Add 3rd hidden layer\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.1))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8A6QLgqm6j7"
      },
      "source": [
        "#Add 3rd hidden layer\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(100, activation='relu'))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SwZobDilZbx"
      },
      "source": [
        "#Add 4th hidden layer\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(30, activation='relu'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFCfODxTld8n"
      },
      "source": [
        "#Add OUTPUT layer\n",
        "\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68XtYGO1o370"
      },
      "source": [
        "adam=tf.keras.optimizers.Adam()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwEaJQqS3_Eh"
      },
      "source": [
        "## Compile the model with loss as categorical cross-entropy and adam optimizers. Use accuracy as the metric for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jTHviKCliHC"
      },
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wZXqXXUpBCh",
        "outputId": "2617e771-2f2e-4763-880f-7fa08b9538d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 750)               768750    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 750)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 750)               3000      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               375500    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 500)               2000      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 200)               100200    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 200)               800       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 30)                3030      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                310       \n",
            "=================================================================\n",
            "Total params: 1,278,186\n",
            "Trainable params: 1,273,038\n",
            "Non-trainable params: 5,148\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb0NMlHqpFIo"
      },
      "source": [
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('svhn_v1.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pltPcAympcH6",
        "outputId": "41f1e621-2acd-40c2-d3be-96950baf3582",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(trainX,trainY,          \n",
        "          validation_data=(valX,valY),\n",
        "          epochs=200,\n",
        "          batch_size=35,callbacks=[model_checkpoint])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 1.7222 - accuracy: 0.4014\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.64020, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 1.7216 - accuracy: 0.4016 - val_loss: 1.1166 - val_accuracy: 0.6402\n",
            "Epoch 2/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 1.2202 - accuracy: 0.6074\n",
            "Epoch 00002: val_accuracy improved from 0.64020 to 0.72835, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 1.2202 - accuracy: 0.6074 - val_loss: 0.8684 - val_accuracy: 0.7283\n",
            "Epoch 3/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 1.0667 - accuracy: 0.6600\n",
            "Epoch 00003: val_accuracy improved from 0.72835 to 0.75225, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 1.0668 - accuracy: 0.6600 - val_loss: 0.7930 - val_accuracy: 0.7523\n",
            "Epoch 4/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.9930 - accuracy: 0.6804\n",
            "Epoch 00004: val_accuracy improved from 0.75225 to 0.77283, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.9932 - accuracy: 0.6803 - val_loss: 0.7275 - val_accuracy: 0.7728\n",
            "Epoch 5/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.9239 - accuracy: 0.7051\n",
            "Epoch 00005: val_accuracy improved from 0.77283 to 0.79783, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 29s 25ms/step - loss: 0.9239 - accuracy: 0.7051 - val_loss: 0.6616 - val_accuracy: 0.7978\n",
            "Epoch 6/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.8773 - accuracy: 0.7213\n",
            "Epoch 00006: val_accuracy improved from 0.79783 to 0.79952, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 29s 25ms/step - loss: 0.8773 - accuracy: 0.7213 - val_loss: 0.6475 - val_accuracy: 0.7995\n",
            "Epoch 7/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.8296 - accuracy: 0.7358\n",
            "Epoch 00007: val_accuracy improved from 0.79952 to 0.80587, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.8297 - accuracy: 0.7358 - val_loss: 0.6167 - val_accuracy: 0.8059\n",
            "Epoch 8/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.8048 - accuracy: 0.7400\n",
            "Epoch 00008: val_accuracy improved from 0.80587 to 0.82835, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.8048 - accuracy: 0.7400 - val_loss: 0.5621 - val_accuracy: 0.8284\n",
            "Epoch 9/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.7779 - accuracy: 0.7538\n",
            "Epoch 00009: val_accuracy improved from 0.82835 to 0.82892, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.7777 - accuracy: 0.7538 - val_loss: 0.5591 - val_accuracy: 0.8289\n",
            "Epoch 10/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.7535 - accuracy: 0.7591\n",
            "Epoch 00010: val_accuracy improved from 0.82892 to 0.84197, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.7536 - accuracy: 0.7591 - val_loss: 0.5142 - val_accuracy: 0.8420\n",
            "Epoch 11/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.7335 - accuracy: 0.7674\n",
            "Epoch 00011: val_accuracy did not improve from 0.84197\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.7336 - accuracy: 0.7673 - val_loss: 0.5162 - val_accuracy: 0.8416\n",
            "Epoch 12/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.7082 - accuracy: 0.7752\n",
            "Epoch 00012: val_accuracy improved from 0.84197 to 0.85127, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.7079 - accuracy: 0.7752 - val_loss: 0.4845 - val_accuracy: 0.8513\n",
            "Epoch 13/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.6955 - accuracy: 0.7802\n",
            "Epoch 00013: val_accuracy improved from 0.85127 to 0.85765, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.6954 - accuracy: 0.7802 - val_loss: 0.4679 - val_accuracy: 0.8576\n",
            "Epoch 14/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.6788 - accuracy: 0.7828\n",
            "Epoch 00014: val_accuracy improved from 0.85765 to 0.86415, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 32s 27ms/step - loss: 0.6789 - accuracy: 0.7827 - val_loss: 0.4527 - val_accuracy: 0.8641\n",
            "Epoch 15/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.6681 - accuracy: 0.7880\n",
            "Epoch 00015: val_accuracy did not improve from 0.86415\n",
            "1200/1200 [==============================] - 32s 26ms/step - loss: 0.6681 - accuracy: 0.7880 - val_loss: 0.4568 - val_accuracy: 0.8598\n",
            "Epoch 16/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.6572 - accuracy: 0.7902\n",
            "Epoch 00016: val_accuracy improved from 0.86415 to 0.86700, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.6570 - accuracy: 0.7902 - val_loss: 0.4319 - val_accuracy: 0.8670\n",
            "Epoch 17/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.6417 - accuracy: 0.7980\n",
            "Epoch 00017: val_accuracy improved from 0.86700 to 0.87315, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.6418 - accuracy: 0.7979 - val_loss: 0.4209 - val_accuracy: 0.8731\n",
            "Epoch 18/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.6384 - accuracy: 0.7956\n",
            "Epoch 00018: val_accuracy improved from 0.87315 to 0.87360, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.6384 - accuracy: 0.7956 - val_loss: 0.4209 - val_accuracy: 0.8736\n",
            "Epoch 19/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.6263 - accuracy: 0.8000\n",
            "Epoch 00019: val_accuracy did not improve from 0.87360\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.6265 - accuracy: 0.8000 - val_loss: 0.4191 - val_accuracy: 0.8727\n",
            "Epoch 20/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.6097 - accuracy: 0.8055\n",
            "Epoch 00020: val_accuracy improved from 0.87360 to 0.87935, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.6098 - accuracy: 0.8054 - val_loss: 0.3963 - val_accuracy: 0.8794\n",
            "Epoch 21/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.6148 - accuracy: 0.8040\n",
            "Epoch 00021: val_accuracy improved from 0.87935 to 0.88148, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.6147 - accuracy: 0.8040 - val_loss: 0.3912 - val_accuracy: 0.8815\n",
            "Epoch 22/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.5999 - accuracy: 0.8086\n",
            "Epoch 00022: val_accuracy improved from 0.88148 to 0.88503, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5997 - accuracy: 0.8086 - val_loss: 0.3799 - val_accuracy: 0.8850\n",
            "Epoch 23/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.5929 - accuracy: 0.8107\n",
            "Epoch 00023: val_accuracy improved from 0.88503 to 0.88692, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.5932 - accuracy: 0.8106 - val_loss: 0.3753 - val_accuracy: 0.8869\n",
            "Epoch 24/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.5775 - accuracy: 0.8145\n",
            "Epoch 00024: val_accuracy improved from 0.88692 to 0.88845, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.5774 - accuracy: 0.8146 - val_loss: 0.3681 - val_accuracy: 0.8885\n",
            "Epoch 25/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.5767 - accuracy: 0.8155\n",
            "Epoch 00025: val_accuracy did not improve from 0.88845\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5767 - accuracy: 0.8155 - val_loss: 0.3695 - val_accuracy: 0.8864\n",
            "Epoch 26/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.5716 - accuracy: 0.8166\n",
            "Epoch 00026: val_accuracy improved from 0.88845 to 0.89070, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5714 - accuracy: 0.8167 - val_loss: 0.3649 - val_accuracy: 0.8907\n",
            "Epoch 27/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.5648 - accuracy: 0.8198\n",
            "Epoch 00027: val_accuracy improved from 0.89070 to 0.89407, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5647 - accuracy: 0.8198 - val_loss: 0.3555 - val_accuracy: 0.8941\n",
            "Epoch 28/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.8198\n",
            "Epoch 00028: val_accuracy improved from 0.89407 to 0.89723, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5659 - accuracy: 0.8198 - val_loss: 0.3471 - val_accuracy: 0.8972\n",
            "Epoch 29/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.5535 - accuracy: 0.8218\n",
            "Epoch 00029: val_accuracy did not improve from 0.89723\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5535 - accuracy: 0.8218 - val_loss: 0.3487 - val_accuracy: 0.8961\n",
            "Epoch 30/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.5432 - accuracy: 0.8265\n",
            "Epoch 00030: val_accuracy did not improve from 0.89723\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5434 - accuracy: 0.8264 - val_loss: 0.3466 - val_accuracy: 0.8961\n",
            "Epoch 31/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.5410 - accuracy: 0.8268\n",
            "Epoch 00031: val_accuracy improved from 0.89723 to 0.90110, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5409 - accuracy: 0.8269 - val_loss: 0.3362 - val_accuracy: 0.9011\n",
            "Epoch 32/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.5439 - accuracy: 0.8258\n",
            "Epoch 00032: val_accuracy improved from 0.90110 to 0.90243, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5438 - accuracy: 0.8258 - val_loss: 0.3319 - val_accuracy: 0.9024\n",
            "Epoch 33/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.8282\n",
            "Epoch 00033: val_accuracy improved from 0.90243 to 0.90265, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5331 - accuracy: 0.8282 - val_loss: 0.3307 - val_accuracy: 0.9026\n",
            "Epoch 34/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.8316\n",
            "Epoch 00034: val_accuracy did not improve from 0.90265\n",
            "1200/1200 [==============================] - 33s 27ms/step - loss: 0.5289 - accuracy: 0.8316 - val_loss: 0.3359 - val_accuracy: 0.9018\n",
            "Epoch 35/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.5280 - accuracy: 0.8295\n",
            "Epoch 00035: val_accuracy improved from 0.90265 to 0.90582, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5281 - accuracy: 0.8295 - val_loss: 0.3197 - val_accuracy: 0.9058\n",
            "Epoch 36/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.5227 - accuracy: 0.8317\n",
            "Epoch 00036: val_accuracy did not improve from 0.90582\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5227 - accuracy: 0.8317 - val_loss: 0.3234 - val_accuracy: 0.9040\n",
            "Epoch 37/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.5124 - accuracy: 0.8348\n",
            "Epoch 00037: val_accuracy did not improve from 0.90582\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5124 - accuracy: 0.8348 - val_loss: 0.3256 - val_accuracy: 0.9051\n",
            "Epoch 38/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.5150 - accuracy: 0.8346\n",
            "Epoch 00038: val_accuracy did not improve from 0.90582\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5150 - accuracy: 0.8346 - val_loss: 0.3184 - val_accuracy: 0.9045\n",
            "Epoch 39/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.5084 - accuracy: 0.8362\n",
            "Epoch 00039: val_accuracy improved from 0.90582 to 0.91073, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 25ms/step - loss: 0.5083 - accuracy: 0.8363 - val_loss: 0.3056 - val_accuracy: 0.9107\n",
            "Epoch 40/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.5029 - accuracy: 0.8390\n",
            "Epoch 00040: val_accuracy did not improve from 0.91073\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.5029 - accuracy: 0.8390 - val_loss: 0.3172 - val_accuracy: 0.9062\n",
            "Epoch 41/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.5001 - accuracy: 0.8407\n",
            "Epoch 00041: val_accuracy did not improve from 0.91073\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.5001 - accuracy: 0.8406 - val_loss: 0.3131 - val_accuracy: 0.9097\n",
            "Epoch 42/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.4994 - accuracy: 0.8394\n",
            "Epoch 00042: val_accuracy improved from 0.91073 to 0.91268, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4994 - accuracy: 0.8394 - val_loss: 0.2999 - val_accuracy: 0.9127\n",
            "Epoch 43/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4911 - accuracy: 0.8432\n",
            "Epoch 00043: val_accuracy did not improve from 0.91268\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4910 - accuracy: 0.8432 - val_loss: 0.3003 - val_accuracy: 0.9112\n",
            "Epoch 44/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4964 - accuracy: 0.8412\n",
            "Epoch 00044: val_accuracy improved from 0.91268 to 0.91287, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.4965 - accuracy: 0.8412 - val_loss: 0.2968 - val_accuracy: 0.9129\n",
            "Epoch 45/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.8430\n",
            "Epoch 00045: val_accuracy did not improve from 0.91287\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.4859 - accuracy: 0.8430 - val_loss: 0.3010 - val_accuracy: 0.9128\n",
            "Epoch 46/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4832 - accuracy: 0.8451\n",
            "Epoch 00046: val_accuracy improved from 0.91287 to 0.91575, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4828 - accuracy: 0.8453 - val_loss: 0.2869 - val_accuracy: 0.9158\n",
            "Epoch 47/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4808 - accuracy: 0.8462\n",
            "Epoch 00047: val_accuracy improved from 0.91575 to 0.91580, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4808 - accuracy: 0.8461 - val_loss: 0.2879 - val_accuracy: 0.9158\n",
            "Epoch 48/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4800 - accuracy: 0.8441\n",
            "Epoch 00048: val_accuracy did not improve from 0.91580\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4797 - accuracy: 0.8443 - val_loss: 0.2889 - val_accuracy: 0.9149\n",
            "Epoch 49/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4785 - accuracy: 0.8470\n",
            "Epoch 00049: val_accuracy did not improve from 0.91580\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4784 - accuracy: 0.8471 - val_loss: 0.2919 - val_accuracy: 0.9139\n",
            "Epoch 50/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4761 - accuracy: 0.8468\n",
            "Epoch 00050: val_accuracy did not improve from 0.91580\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4761 - accuracy: 0.8468 - val_loss: 0.2897 - val_accuracy: 0.9152\n",
            "Epoch 51/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4708 - accuracy: 0.8481\n",
            "Epoch 00051: val_accuracy improved from 0.91580 to 0.91750, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.4707 - accuracy: 0.8481 - val_loss: 0.2837 - val_accuracy: 0.9175\n",
            "Epoch 52/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4658 - accuracy: 0.8502\n",
            "Epoch 00052: val_accuracy did not improve from 0.91750\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4657 - accuracy: 0.8501 - val_loss: 0.2807 - val_accuracy: 0.9172\n",
            "Epoch 53/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4649 - accuracy: 0.8501\n",
            "Epoch 00053: val_accuracy improved from 0.91750 to 0.92005, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4648 - accuracy: 0.8502 - val_loss: 0.2783 - val_accuracy: 0.9201\n",
            "Epoch 54/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4556 - accuracy: 0.8528\n",
            "Epoch 00054: val_accuracy did not improve from 0.92005\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.4554 - accuracy: 0.8528 - val_loss: 0.2727 - val_accuracy: 0.9197\n",
            "Epoch 55/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4625 - accuracy: 0.8518\n",
            "Epoch 00055: val_accuracy improved from 0.92005 to 0.92210, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.4625 - accuracy: 0.8518 - val_loss: 0.2687 - val_accuracy: 0.9221\n",
            "Epoch 56/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4561 - accuracy: 0.8535\n",
            "Epoch 00056: val_accuracy did not improve from 0.92210\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4559 - accuracy: 0.8536 - val_loss: 0.2702 - val_accuracy: 0.9217\n",
            "Epoch 57/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.4620 - accuracy: 0.8485\n",
            "Epoch 00057: val_accuracy did not improve from 0.92210\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4620 - accuracy: 0.8485 - val_loss: 0.2724 - val_accuracy: 0.9211\n",
            "Epoch 58/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.4537 - accuracy: 0.8544\n",
            "Epoch 00058: val_accuracy improved from 0.92210 to 0.92535, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4537 - accuracy: 0.8544 - val_loss: 0.2604 - val_accuracy: 0.9254\n",
            "Epoch 59/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4561 - accuracy: 0.8532\n",
            "Epoch 00059: val_accuracy improved from 0.92535 to 0.92672, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4561 - accuracy: 0.8533 - val_loss: 0.2570 - val_accuracy: 0.9267\n",
            "Epoch 60/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4483 - accuracy: 0.8564\n",
            "Epoch 00060: val_accuracy did not improve from 0.92672\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4484 - accuracy: 0.8563 - val_loss: 0.2665 - val_accuracy: 0.9246\n",
            "Epoch 61/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4509 - accuracy: 0.8563\n",
            "Epoch 00061: val_accuracy improved from 0.92672 to 0.92683, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4509 - accuracy: 0.8562 - val_loss: 0.2565 - val_accuracy: 0.9268\n",
            "Epoch 62/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.8554\n",
            "Epoch 00062: val_accuracy improved from 0.92683 to 0.92722, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4508 - accuracy: 0.8554 - val_loss: 0.2541 - val_accuracy: 0.9272\n",
            "Epoch 63/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4412 - accuracy: 0.8576\n",
            "Epoch 00063: val_accuracy did not improve from 0.92722\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4413 - accuracy: 0.8575 - val_loss: 0.2628 - val_accuracy: 0.9233\n",
            "Epoch 64/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4365 - accuracy: 0.8576\n",
            "Epoch 00064: val_accuracy did not improve from 0.92722\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4365 - accuracy: 0.8576 - val_loss: 0.2583 - val_accuracy: 0.9257\n",
            "Epoch 65/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4419 - accuracy: 0.8562\n",
            "Epoch 00065: val_accuracy did not improve from 0.92722\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.4421 - accuracy: 0.8561 - val_loss: 0.2581 - val_accuracy: 0.9268\n",
            "Epoch 66/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4307 - accuracy: 0.8596\n",
            "Epoch 00066: val_accuracy improved from 0.92722 to 0.92820, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4307 - accuracy: 0.8596 - val_loss: 0.2502 - val_accuracy: 0.9282\n",
            "Epoch 67/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4364 - accuracy: 0.8575\n",
            "Epoch 00067: val_accuracy did not improve from 0.92820\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4363 - accuracy: 0.8576 - val_loss: 0.2534 - val_accuracy: 0.9279\n",
            "Epoch 68/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4375 - accuracy: 0.8601\n",
            "Epoch 00068: val_accuracy did not improve from 0.92820\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4374 - accuracy: 0.8601 - val_loss: 0.2602 - val_accuracy: 0.9270\n",
            "Epoch 69/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4307 - accuracy: 0.8612\n",
            "Epoch 00069: val_accuracy improved from 0.92820 to 0.92985, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4306 - accuracy: 0.8612 - val_loss: 0.2480 - val_accuracy: 0.9298\n",
            "Epoch 70/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4285 - accuracy: 0.8619\n",
            "Epoch 00070: val_accuracy did not improve from 0.92985\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4284 - accuracy: 0.8618 - val_loss: 0.2520 - val_accuracy: 0.9279\n",
            "Epoch 71/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4296 - accuracy: 0.8629\n",
            "Epoch 00071: val_accuracy did not improve from 0.92985\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4294 - accuracy: 0.8629 - val_loss: 0.2549 - val_accuracy: 0.9243\n",
            "Epoch 72/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4224 - accuracy: 0.8642\n",
            "Epoch 00072: val_accuracy did not improve from 0.92985\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4223 - accuracy: 0.8643 - val_loss: 0.2489 - val_accuracy: 0.9287\n",
            "Epoch 73/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4276 - accuracy: 0.8627\n",
            "Epoch 00073: val_accuracy improved from 0.92985 to 0.93053, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4276 - accuracy: 0.8628 - val_loss: 0.2446 - val_accuracy: 0.9305\n",
            "Epoch 74/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4244 - accuracy: 0.8610\n",
            "Epoch 00074: val_accuracy did not improve from 0.93053\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4246 - accuracy: 0.8609 - val_loss: 0.2509 - val_accuracy: 0.9276\n",
            "Epoch 75/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4190 - accuracy: 0.8642\n",
            "Epoch 00075: val_accuracy improved from 0.93053 to 0.93183, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 32s 27ms/step - loss: 0.4194 - accuracy: 0.8641 - val_loss: 0.2401 - val_accuracy: 0.9318\n",
            "Epoch 76/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.4160 - accuracy: 0.8663\n",
            "Epoch 00076: val_accuracy improved from 0.93183 to 0.93435, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4160 - accuracy: 0.8663 - val_loss: 0.2367 - val_accuracy: 0.9344\n",
            "Epoch 77/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4089 - accuracy: 0.8682\n",
            "Epoch 00077: val_accuracy did not improve from 0.93435\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4089 - accuracy: 0.8682 - val_loss: 0.2373 - val_accuracy: 0.9331\n",
            "Epoch 78/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4149 - accuracy: 0.8646\n",
            "Epoch 00078: val_accuracy did not improve from 0.93435\n",
            "1200/1200 [==============================] - 31s 25ms/step - loss: 0.4153 - accuracy: 0.8645 - val_loss: 0.2434 - val_accuracy: 0.9305\n",
            "Epoch 79/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4178 - accuracy: 0.8668\n",
            "Epoch 00079: val_accuracy did not improve from 0.93435\n",
            "1200/1200 [==============================] - 31s 25ms/step - loss: 0.4177 - accuracy: 0.8669 - val_loss: 0.2364 - val_accuracy: 0.9333\n",
            "Epoch 80/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4146 - accuracy: 0.8656\n",
            "Epoch 00080: val_accuracy did not improve from 0.93435\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4147 - accuracy: 0.8655 - val_loss: 0.2386 - val_accuracy: 0.9322\n",
            "Epoch 81/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.8685\n",
            "Epoch 00081: val_accuracy improved from 0.93435 to 0.93460, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.4072 - accuracy: 0.8685 - val_loss: 0.2295 - val_accuracy: 0.9346\n",
            "Epoch 82/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4068 - accuracy: 0.8676\n",
            "Epoch 00082: val_accuracy did not improve from 0.93460\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.4070 - accuracy: 0.8675 - val_loss: 0.2352 - val_accuracy: 0.9339\n",
            "Epoch 83/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.4080 - accuracy: 0.8680\n",
            "Epoch 00083: val_accuracy did not improve from 0.93460\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.4081 - accuracy: 0.8680 - val_loss: 0.2365 - val_accuracy: 0.9338\n",
            "Epoch 84/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.4064 - accuracy: 0.8689\n",
            "Epoch 00084: val_accuracy did not improve from 0.93460\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.4063 - accuracy: 0.8689 - val_loss: 0.2373 - val_accuracy: 0.9334\n",
            "Epoch 85/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.4006 - accuracy: 0.8696\n",
            "Epoch 00085: val_accuracy did not improve from 0.93460\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.4006 - accuracy: 0.8696 - val_loss: 0.2394 - val_accuracy: 0.9316\n",
            "Epoch 86/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3990 - accuracy: 0.8717\n",
            "Epoch 00086: val_accuracy improved from 0.93460 to 0.93473, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 33s 27ms/step - loss: 0.3991 - accuracy: 0.8718 - val_loss: 0.2323 - val_accuracy: 0.9347\n",
            "Epoch 87/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3995 - accuracy: 0.8710\n",
            "Epoch 00087: val_accuracy improved from 0.93473 to 0.93648, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3996 - accuracy: 0.8710 - val_loss: 0.2268 - val_accuracy: 0.9365\n",
            "Epoch 88/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3987 - accuracy: 0.8708\n",
            "Epoch 00088: val_accuracy did not improve from 0.93648\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3987 - accuracy: 0.8708 - val_loss: 0.2274 - val_accuracy: 0.9360\n",
            "Epoch 89/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3968 - accuracy: 0.8718\n",
            "Epoch 00089: val_accuracy did not improve from 0.93648\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3968 - accuracy: 0.8718 - val_loss: 0.2300 - val_accuracy: 0.9356\n",
            "Epoch 90/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3993 - accuracy: 0.8695\n",
            "Epoch 00090: val_accuracy did not improve from 0.93648\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3993 - accuracy: 0.8695 - val_loss: 0.2355 - val_accuracy: 0.9338\n",
            "Epoch 91/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3953 - accuracy: 0.8725\n",
            "Epoch 00091: val_accuracy did not improve from 0.93648\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3954 - accuracy: 0.8725 - val_loss: 0.2317 - val_accuracy: 0.9357\n",
            "Epoch 92/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.8732\n",
            "Epoch 00092: val_accuracy improved from 0.93648 to 0.93703, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3952 - accuracy: 0.8732 - val_loss: 0.2247 - val_accuracy: 0.9370\n",
            "Epoch 93/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3929 - accuracy: 0.8739\n",
            "Epoch 00093: val_accuracy did not improve from 0.93703\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3930 - accuracy: 0.8739 - val_loss: 0.2310 - val_accuracy: 0.9351\n",
            "Epoch 94/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3905 - accuracy: 0.8731\n",
            "Epoch 00094: val_accuracy did not improve from 0.93703\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3905 - accuracy: 0.8731 - val_loss: 0.2327 - val_accuracy: 0.9338\n",
            "Epoch 95/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.8742\n",
            "Epoch 00095: val_accuracy did not improve from 0.93703\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3893 - accuracy: 0.8742 - val_loss: 0.2334 - val_accuracy: 0.9348\n",
            "Epoch 96/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8754\n",
            "Epoch 00096: val_accuracy improved from 0.93703 to 0.94020, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3859 - accuracy: 0.8755 - val_loss: 0.2154 - val_accuracy: 0.9402\n",
            "Epoch 97/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3939 - accuracy: 0.8735\n",
            "Epoch 00097: val_accuracy did not improve from 0.94020\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3936 - accuracy: 0.8736 - val_loss: 0.2216 - val_accuracy: 0.9385\n",
            "Epoch 98/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8751\n",
            "Epoch 00098: val_accuracy did not improve from 0.94020\n",
            "1200/1200 [==============================] - 31s 25ms/step - loss: 0.3820 - accuracy: 0.8751 - val_loss: 0.2144 - val_accuracy: 0.9401\n",
            "Epoch 99/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8745\n",
            "Epoch 00099: val_accuracy did not improve from 0.94020\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3870 - accuracy: 0.8745 - val_loss: 0.2226 - val_accuracy: 0.9384\n",
            "Epoch 100/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8758\n",
            "Epoch 00100: val_accuracy did not improve from 0.94020\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3873 - accuracy: 0.8759 - val_loss: 0.2182 - val_accuracy: 0.9401\n",
            "Epoch 101/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3778 - accuracy: 0.8763\n",
            "Epoch 00101: val_accuracy did not improve from 0.94020\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3778 - accuracy: 0.8763 - val_loss: 0.2223 - val_accuracy: 0.9378\n",
            "Epoch 102/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8778\n",
            "Epoch 00102: val_accuracy did not improve from 0.94020\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3832 - accuracy: 0.8778 - val_loss: 0.2161 - val_accuracy: 0.9402\n",
            "Epoch 103/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8787\n",
            "Epoch 00103: val_accuracy did not improve from 0.94020\n",
            "1200/1200 [==============================] - 31s 25ms/step - loss: 0.3788 - accuracy: 0.8787 - val_loss: 0.2226 - val_accuracy: 0.9389\n",
            "Epoch 104/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8769\n",
            "Epoch 00104: val_accuracy did not improve from 0.94020\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3834 - accuracy: 0.8769 - val_loss: 0.2238 - val_accuracy: 0.9374\n",
            "Epoch 105/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8767\n",
            "Epoch 00105: val_accuracy did not improve from 0.94020\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3805 - accuracy: 0.8767 - val_loss: 0.2178 - val_accuracy: 0.9400\n",
            "Epoch 106/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8742\n",
            "Epoch 00106: val_accuracy did not improve from 0.94020\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3801 - accuracy: 0.8741 - val_loss: 0.2151 - val_accuracy: 0.9399\n",
            "Epoch 107/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3721 - accuracy: 0.8797\n",
            "Epoch 00107: val_accuracy did not improve from 0.94020\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3722 - accuracy: 0.8796 - val_loss: 0.2172 - val_accuracy: 0.9394\n",
            "Epoch 108/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3726 - accuracy: 0.8798\n",
            "Epoch 00108: val_accuracy improved from 0.94020 to 0.94067, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3729 - accuracy: 0.8797 - val_loss: 0.2131 - val_accuracy: 0.9407\n",
            "Epoch 109/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8744\n",
            "Epoch 00109: val_accuracy improved from 0.94067 to 0.94088, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 25ms/step - loss: 0.3811 - accuracy: 0.8744 - val_loss: 0.2121 - val_accuracy: 0.9409\n",
            "Epoch 110/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3736 - accuracy: 0.8791\n",
            "Epoch 00110: val_accuracy improved from 0.94088 to 0.94147, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 25ms/step - loss: 0.3736 - accuracy: 0.8791 - val_loss: 0.2126 - val_accuracy: 0.9415\n",
            "Epoch 111/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3728 - accuracy: 0.8791\n",
            "Epoch 00111: val_accuracy improved from 0.94147 to 0.94295, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3729 - accuracy: 0.8790 - val_loss: 0.2079 - val_accuracy: 0.9430\n",
            "Epoch 112/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3652 - accuracy: 0.8811\n",
            "Epoch 00112: val_accuracy did not improve from 0.94295\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3652 - accuracy: 0.8811 - val_loss: 0.2140 - val_accuracy: 0.9390\n",
            "Epoch 113/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3718 - accuracy: 0.8809\n",
            "Epoch 00113: val_accuracy did not improve from 0.94295\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3718 - accuracy: 0.8809 - val_loss: 0.2096 - val_accuracy: 0.9427\n",
            "Epoch 114/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3637 - accuracy: 0.8823\n",
            "Epoch 00114: val_accuracy did not improve from 0.94295\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3636 - accuracy: 0.8823 - val_loss: 0.2094 - val_accuracy: 0.9413\n",
            "Epoch 115/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.8815\n",
            "Epoch 00115: val_accuracy did not improve from 0.94295\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3659 - accuracy: 0.8815 - val_loss: 0.2113 - val_accuracy: 0.9408\n",
            "Epoch 116/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3678 - accuracy: 0.8836\n",
            "Epoch 00116: val_accuracy did not improve from 0.94295\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3679 - accuracy: 0.8835 - val_loss: 0.2164 - val_accuracy: 0.9401\n",
            "Epoch 117/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3683 - accuracy: 0.8805\n",
            "Epoch 00117: val_accuracy did not improve from 0.94295\n",
            "1200/1200 [==============================] - 31s 25ms/step - loss: 0.3682 - accuracy: 0.8806 - val_loss: 0.2064 - val_accuracy: 0.9419\n",
            "Epoch 118/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3712 - accuracy: 0.8793\n",
            "Epoch 00118: val_accuracy did not improve from 0.94295\n",
            "1200/1200 [==============================] - 31s 25ms/step - loss: 0.3709 - accuracy: 0.8794 - val_loss: 0.2113 - val_accuracy: 0.9424\n",
            "Epoch 119/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3648 - accuracy: 0.8820\n",
            "Epoch 00119: val_accuracy did not improve from 0.94295\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3647 - accuracy: 0.8821 - val_loss: 0.2093 - val_accuracy: 0.9421\n",
            "Epoch 120/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3612 - accuracy: 0.8831\n",
            "Epoch 00120: val_accuracy improved from 0.94295 to 0.94325, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3613 - accuracy: 0.8830 - val_loss: 0.2066 - val_accuracy: 0.9433\n",
            "Epoch 121/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.8833\n",
            "Epoch 00121: val_accuracy improved from 0.94325 to 0.94535, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3596 - accuracy: 0.8833 - val_loss: 0.2036 - val_accuracy: 0.9453\n",
            "Epoch 122/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3591 - accuracy: 0.8838\n",
            "Epoch 00122: val_accuracy did not improve from 0.94535\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3591 - accuracy: 0.8838 - val_loss: 0.2092 - val_accuracy: 0.9416\n",
            "Epoch 123/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3557 - accuracy: 0.8835\n",
            "Epoch 00123: val_accuracy did not improve from 0.94535\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3557 - accuracy: 0.8835 - val_loss: 0.2038 - val_accuracy: 0.9443\n",
            "Epoch 124/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.8830\n",
            "Epoch 00124: val_accuracy improved from 0.94535 to 0.94558, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 32s 26ms/step - loss: 0.3606 - accuracy: 0.8830 - val_loss: 0.2043 - val_accuracy: 0.9456\n",
            "Epoch 125/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.8827\n",
            "Epoch 00125: val_accuracy did not improve from 0.94558\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3596 - accuracy: 0.8827 - val_loss: 0.2042 - val_accuracy: 0.9438\n",
            "Epoch 126/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3553 - accuracy: 0.8862\n",
            "Epoch 00126: val_accuracy did not improve from 0.94558\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.3552 - accuracy: 0.8862 - val_loss: 0.2074 - val_accuracy: 0.9449\n",
            "Epoch 127/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3574 - accuracy: 0.8836\n",
            "Epoch 00127: val_accuracy did not improve from 0.94558\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3575 - accuracy: 0.8836 - val_loss: 0.2061 - val_accuracy: 0.9429\n",
            "Epoch 128/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3651 - accuracy: 0.8812\n",
            "Epoch 00128: val_accuracy did not improve from 0.94558\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3651 - accuracy: 0.8812 - val_loss: 0.2046 - val_accuracy: 0.9430\n",
            "Epoch 129/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3598 - accuracy: 0.8844\n",
            "Epoch 00129: val_accuracy improved from 0.94558 to 0.94568, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3598 - accuracy: 0.8844 - val_loss: 0.1998 - val_accuracy: 0.9457\n",
            "Epoch 130/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3538 - accuracy: 0.8838\n",
            "Epoch 00130: val_accuracy improved from 0.94568 to 0.94580, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3536 - accuracy: 0.8838 - val_loss: 0.2025 - val_accuracy: 0.9458\n",
            "Epoch 131/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3575 - accuracy: 0.8850\n",
            "Epoch 00131: val_accuracy improved from 0.94580 to 0.94702, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3576 - accuracy: 0.8849 - val_loss: 0.1960 - val_accuracy: 0.9470\n",
            "Epoch 132/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3543 - accuracy: 0.8837\n",
            "Epoch 00132: val_accuracy did not improve from 0.94702\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3545 - accuracy: 0.8836 - val_loss: 0.2035 - val_accuracy: 0.9443\n",
            "Epoch 133/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3520 - accuracy: 0.8862\n",
            "Epoch 00133: val_accuracy did not improve from 0.94702\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3522 - accuracy: 0.8861 - val_loss: 0.1971 - val_accuracy: 0.9455\n",
            "Epoch 134/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8869\n",
            "Epoch 00134: val_accuracy did not improve from 0.94702\n",
            "1200/1200 [==============================] - 32s 26ms/step - loss: 0.3494 - accuracy: 0.8869 - val_loss: 0.1984 - val_accuracy: 0.9449\n",
            "Epoch 135/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.8868\n",
            "Epoch 00135: val_accuracy did not improve from 0.94702\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3452 - accuracy: 0.8868 - val_loss: 0.1994 - val_accuracy: 0.9464\n",
            "Epoch 136/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3477 - accuracy: 0.8870\n",
            "Epoch 00136: val_accuracy did not improve from 0.94702\n",
            "1200/1200 [==============================] - 32s 27ms/step - loss: 0.3476 - accuracy: 0.8870 - val_loss: 0.2013 - val_accuracy: 0.9455\n",
            "Epoch 137/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3456 - accuracy: 0.8857\n",
            "Epoch 00137: val_accuracy did not improve from 0.94702\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3454 - accuracy: 0.8857 - val_loss: 0.2050 - val_accuracy: 0.9436\n",
            "Epoch 138/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3440 - accuracy: 0.8879\n",
            "Epoch 00138: val_accuracy did not improve from 0.94702\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3440 - accuracy: 0.8878 - val_loss: 0.1964 - val_accuracy: 0.9458\n",
            "Epoch 139/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 0.8880\n",
            "Epoch 00139: val_accuracy did not improve from 0.94702\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3446 - accuracy: 0.8880 - val_loss: 0.1957 - val_accuracy: 0.9460\n",
            "Epoch 140/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3470 - accuracy: 0.8882\n",
            "Epoch 00140: val_accuracy did not improve from 0.94702\n",
            "1200/1200 [==============================] - 32s 26ms/step - loss: 0.3472 - accuracy: 0.8881 - val_loss: 0.1987 - val_accuracy: 0.9449\n",
            "Epoch 141/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3456 - accuracy: 0.8884\n",
            "Epoch 00141: val_accuracy did not improve from 0.94702\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3455 - accuracy: 0.8884 - val_loss: 0.2000 - val_accuracy: 0.9446\n",
            "Epoch 142/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3416 - accuracy: 0.8879\n",
            "Epoch 00142: val_accuracy improved from 0.94702 to 0.94882, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 32s 26ms/step - loss: 0.3416 - accuracy: 0.8879 - val_loss: 0.1896 - val_accuracy: 0.9488\n",
            "Epoch 143/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3457 - accuracy: 0.8882\n",
            "Epoch 00143: val_accuracy did not improve from 0.94882\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3457 - accuracy: 0.8882 - val_loss: 0.1963 - val_accuracy: 0.9455\n",
            "Epoch 144/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3377 - accuracy: 0.8910\n",
            "Epoch 00144: val_accuracy did not improve from 0.94882\n",
            "1200/1200 [==============================] - 32s 26ms/step - loss: 0.3377 - accuracy: 0.8910 - val_loss: 0.1997 - val_accuracy: 0.9438\n",
            "Epoch 145/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3403 - accuracy: 0.8896\n",
            "Epoch 00145: val_accuracy did not improve from 0.94882\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3402 - accuracy: 0.8895 - val_loss: 0.1966 - val_accuracy: 0.9467\n",
            "Epoch 146/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3405 - accuracy: 0.8892\n",
            "Epoch 00146: val_accuracy did not improve from 0.94882\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3405 - accuracy: 0.8892 - val_loss: 0.1968 - val_accuracy: 0.9460\n",
            "Epoch 147/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.8903\n",
            "Epoch 00147: val_accuracy did not improve from 0.94882\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3399 - accuracy: 0.8903 - val_loss: 0.1912 - val_accuracy: 0.9470\n",
            "Epoch 148/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3371 - accuracy: 0.8901\n",
            "Epoch 00148: val_accuracy did not improve from 0.94882\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3372 - accuracy: 0.8900 - val_loss: 0.1938 - val_accuracy: 0.9480\n",
            "Epoch 149/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3398 - accuracy: 0.8905\n",
            "Epoch 00149: val_accuracy did not improve from 0.94882\n",
            "1200/1200 [==============================] - 29s 25ms/step - loss: 0.3398 - accuracy: 0.8905 - val_loss: 0.1979 - val_accuracy: 0.9455\n",
            "Epoch 150/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3387 - accuracy: 0.8896\n",
            "Epoch 00150: val_accuracy did not improve from 0.94882\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3388 - accuracy: 0.8896 - val_loss: 0.1981 - val_accuracy: 0.9447\n",
            "Epoch 151/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3423 - accuracy: 0.8901\n",
            "Epoch 00151: val_accuracy improved from 0.94882 to 0.95000, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 29s 25ms/step - loss: 0.3423 - accuracy: 0.8901 - val_loss: 0.1883 - val_accuracy: 0.9500\n",
            "Epoch 152/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3415 - accuracy: 0.8897\n",
            "Epoch 00152: val_accuracy did not improve from 0.95000\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3415 - accuracy: 0.8897 - val_loss: 0.1956 - val_accuracy: 0.9467\n",
            "Epoch 153/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.8920\n",
            "Epoch 00153: val_accuracy did not improve from 0.95000\n",
            "1200/1200 [==============================] - 29s 25ms/step - loss: 0.3333 - accuracy: 0.8920 - val_loss: 0.1896 - val_accuracy: 0.9488\n",
            "Epoch 154/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3319 - accuracy: 0.8920\n",
            "Epoch 00154: val_accuracy did not improve from 0.95000\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3322 - accuracy: 0.8920 - val_loss: 0.1911 - val_accuracy: 0.9483\n",
            "Epoch 155/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3437 - accuracy: 0.8879\n",
            "Epoch 00155: val_accuracy improved from 0.95000 to 0.95072, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3436 - accuracy: 0.8879 - val_loss: 0.1859 - val_accuracy: 0.9507\n",
            "Epoch 156/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3359 - accuracy: 0.8901\n",
            "Epoch 00156: val_accuracy did not improve from 0.95072\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3359 - accuracy: 0.8901 - val_loss: 0.1882 - val_accuracy: 0.9482\n",
            "Epoch 157/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3338 - accuracy: 0.8914\n",
            "Epoch 00157: val_accuracy did not improve from 0.95072\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3338 - accuracy: 0.8914 - val_loss: 0.1840 - val_accuracy: 0.9498\n",
            "Epoch 158/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3339 - accuracy: 0.8904\n",
            "Epoch 00158: val_accuracy did not improve from 0.95072\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3339 - accuracy: 0.8905 - val_loss: 0.1878 - val_accuracy: 0.9497\n",
            "Epoch 159/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3306 - accuracy: 0.8916\n",
            "Epoch 00159: val_accuracy did not improve from 0.95072\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3306 - accuracy: 0.8916 - val_loss: 0.1957 - val_accuracy: 0.9470\n",
            "Epoch 160/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3320 - accuracy: 0.8931\n",
            "Epoch 00160: val_accuracy did not improve from 0.95072\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3320 - accuracy: 0.8931 - val_loss: 0.1909 - val_accuracy: 0.9480\n",
            "Epoch 161/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3300 - accuracy: 0.8920\n",
            "Epoch 00161: val_accuracy did not improve from 0.95072\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3300 - accuracy: 0.8921 - val_loss: 0.1904 - val_accuracy: 0.9476\n",
            "Epoch 162/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.8901\n",
            "Epoch 00162: val_accuracy did not improve from 0.95072\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3305 - accuracy: 0.8901 - val_loss: 0.1883 - val_accuracy: 0.9486\n",
            "Epoch 163/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3356 - accuracy: 0.8924\n",
            "Epoch 00163: val_accuracy did not improve from 0.95072\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3356 - accuracy: 0.8924 - val_loss: 0.1842 - val_accuracy: 0.9507\n",
            "Epoch 164/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3253 - accuracy: 0.8951\n",
            "Epoch 00164: val_accuracy did not improve from 0.95072\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3253 - accuracy: 0.8951 - val_loss: 0.1877 - val_accuracy: 0.9498\n",
            "Epoch 165/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3278 - accuracy: 0.8916\n",
            "Epoch 00165: val_accuracy did not improve from 0.95072\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3278 - accuracy: 0.8916 - val_loss: 0.1830 - val_accuracy: 0.9503\n",
            "Epoch 166/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3238 - accuracy: 0.8959\n",
            "Epoch 00166: val_accuracy did not improve from 0.95072\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3238 - accuracy: 0.8959 - val_loss: 0.1845 - val_accuracy: 0.9496\n",
            "Epoch 167/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3333 - accuracy: 0.8899\n",
            "Epoch 00167: val_accuracy did not improve from 0.95072\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3333 - accuracy: 0.8899 - val_loss: 0.1852 - val_accuracy: 0.9497\n",
            "Epoch 168/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3238 - accuracy: 0.8952\n",
            "Epoch 00168: val_accuracy did not improve from 0.95072\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3238 - accuracy: 0.8952 - val_loss: 0.1863 - val_accuracy: 0.9485\n",
            "Epoch 169/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3242 - accuracy: 0.8944\n",
            "Epoch 00169: val_accuracy improved from 0.95072 to 0.95198, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 29s 25ms/step - loss: 0.3242 - accuracy: 0.8944 - val_loss: 0.1809 - val_accuracy: 0.9520\n",
            "Epoch 170/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3262 - accuracy: 0.8934\n",
            "Epoch 00170: val_accuracy did not improve from 0.95198\n",
            "1200/1200 [==============================] - 29s 25ms/step - loss: 0.3260 - accuracy: 0.8935 - val_loss: 0.1828 - val_accuracy: 0.9502\n",
            "Epoch 171/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3271 - accuracy: 0.8941\n",
            "Epoch 00171: val_accuracy did not improve from 0.95198\n",
            "1200/1200 [==============================] - 29s 25ms/step - loss: 0.3268 - accuracy: 0.8942 - val_loss: 0.1822 - val_accuracy: 0.9506\n",
            "Epoch 172/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3246 - accuracy: 0.8951\n",
            "Epoch 00172: val_accuracy did not improve from 0.95198\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3246 - accuracy: 0.8951 - val_loss: 0.1906 - val_accuracy: 0.9475\n",
            "Epoch 173/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3183 - accuracy: 0.8953\n",
            "Epoch 00173: val_accuracy did not improve from 0.95198\n",
            "1200/1200 [==============================] - 29s 25ms/step - loss: 0.3183 - accuracy: 0.8953 - val_loss: 0.1900 - val_accuracy: 0.9470\n",
            "Epoch 174/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.8949\n",
            "Epoch 00174: val_accuracy did not improve from 0.95198\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3251 - accuracy: 0.8949 - val_loss: 0.1818 - val_accuracy: 0.9505\n",
            "Epoch 175/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3225 - accuracy: 0.8947\n",
            "Epoch 00175: val_accuracy did not improve from 0.95198\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3223 - accuracy: 0.8947 - val_loss: 0.1797 - val_accuracy: 0.9516\n",
            "Epoch 176/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3234 - accuracy: 0.8935\n",
            "Epoch 00176: val_accuracy did not improve from 0.95198\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3234 - accuracy: 0.8935 - val_loss: 0.1850 - val_accuracy: 0.9496\n",
            "Epoch 177/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3196 - accuracy: 0.8951\n",
            "Epoch 00177: val_accuracy did not improve from 0.95198\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3197 - accuracy: 0.8949 - val_loss: 0.1857 - val_accuracy: 0.9500\n",
            "Epoch 178/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3292 - accuracy: 0.8916\n",
            "Epoch 00178: val_accuracy did not improve from 0.95198\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3291 - accuracy: 0.8917 - val_loss: 0.1820 - val_accuracy: 0.9513\n",
            "Epoch 179/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3209 - accuracy: 0.8957\n",
            "Epoch 00179: val_accuracy did not improve from 0.95198\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3209 - accuracy: 0.8957 - val_loss: 0.1782 - val_accuracy: 0.9519\n",
            "Epoch 180/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3232 - accuracy: 0.8947\n",
            "Epoch 00180: val_accuracy did not improve from 0.95198\n",
            "1200/1200 [==============================] - 29s 25ms/step - loss: 0.3231 - accuracy: 0.8947 - val_loss: 0.1823 - val_accuracy: 0.9514\n",
            "Epoch 181/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3156 - accuracy: 0.8962\n",
            "Epoch 00181: val_accuracy did not improve from 0.95198\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3155 - accuracy: 0.8962 - val_loss: 0.1799 - val_accuracy: 0.9514\n",
            "Epoch 182/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3181 - accuracy: 0.8955\n",
            "Epoch 00182: val_accuracy did not improve from 0.95198\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3183 - accuracy: 0.8955 - val_loss: 0.1829 - val_accuracy: 0.9503\n",
            "Epoch 183/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3190 - accuracy: 0.8962\n",
            "Epoch 00183: val_accuracy improved from 0.95198 to 0.95232, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3191 - accuracy: 0.8962 - val_loss: 0.1776 - val_accuracy: 0.9523\n",
            "Epoch 184/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3129 - accuracy: 0.8977\n",
            "Epoch 00184: val_accuracy did not improve from 0.95232\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3129 - accuracy: 0.8977 - val_loss: 0.1795 - val_accuracy: 0.9516\n",
            "Epoch 185/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3204 - accuracy: 0.8964\n",
            "Epoch 00185: val_accuracy did not improve from 0.95232\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3205 - accuracy: 0.8963 - val_loss: 0.1794 - val_accuracy: 0.9507\n",
            "Epoch 186/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3105 - accuracy: 0.8991\n",
            "Epoch 00186: val_accuracy improved from 0.95232 to 0.95308, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 29s 25ms/step - loss: 0.3105 - accuracy: 0.8991 - val_loss: 0.1781 - val_accuracy: 0.9531\n",
            "Epoch 187/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3212 - accuracy: 0.8945\n",
            "Epoch 00187: val_accuracy did not improve from 0.95308\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3210 - accuracy: 0.8946 - val_loss: 0.1815 - val_accuracy: 0.9520\n",
            "Epoch 188/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3126 - accuracy: 0.8976\n",
            "Epoch 00188: val_accuracy did not improve from 0.95308\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3126 - accuracy: 0.8976 - val_loss: 0.1802 - val_accuracy: 0.9521\n",
            "Epoch 189/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3158 - accuracy: 0.8955\n",
            "Epoch 00189: val_accuracy did not improve from 0.95308\n",
            "1200/1200 [==============================] - 31s 26ms/step - loss: 0.3159 - accuracy: 0.8954 - val_loss: 0.1949 - val_accuracy: 0.9469\n",
            "Epoch 190/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.8950\n",
            "Epoch 00190: val_accuracy did not improve from 0.95308\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3224 - accuracy: 0.8950 - val_loss: 0.1804 - val_accuracy: 0.9521\n",
            "Epoch 191/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3114 - accuracy: 0.8991\n",
            "Epoch 00191: val_accuracy did not improve from 0.95308\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3115 - accuracy: 0.8990 - val_loss: 0.1785 - val_accuracy: 0.9528\n",
            "Epoch 192/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3118 - accuracy: 0.8996\n",
            "Epoch 00192: val_accuracy improved from 0.95308 to 0.95375, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3121 - accuracy: 0.8995 - val_loss: 0.1741 - val_accuracy: 0.9538\n",
            "Epoch 193/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3134 - accuracy: 0.8967\n",
            "Epoch 00193: val_accuracy did not improve from 0.95375\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3134 - accuracy: 0.8966 - val_loss: 0.1821 - val_accuracy: 0.9509\n",
            "Epoch 194/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3137 - accuracy: 0.8973\n",
            "Epoch 00194: val_accuracy did not improve from 0.95375\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3137 - accuracy: 0.8973 - val_loss: 0.1764 - val_accuracy: 0.9530\n",
            "Epoch 195/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3119 - accuracy: 0.8983\n",
            "Epoch 00195: val_accuracy did not improve from 0.95375\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.3119 - accuracy: 0.8984 - val_loss: 0.1757 - val_accuracy: 0.9537\n",
            "Epoch 196/200\n",
            "1199/1200 [============================>.] - ETA: 0s - loss: 0.3113 - accuracy: 0.8975\n",
            "Epoch 00196: val_accuracy did not improve from 0.95375\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3112 - accuracy: 0.8975 - val_loss: 0.1779 - val_accuracy: 0.9524\n",
            "Epoch 197/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3122 - accuracy: 0.8986\n",
            "Epoch 00197: val_accuracy did not improve from 0.95375\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3122 - accuracy: 0.8986 - val_loss: 0.1769 - val_accuracy: 0.9536\n",
            "Epoch 198/200\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.8992\n",
            "Epoch 00198: val_accuracy did not improve from 0.95375\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3100 - accuracy: 0.8992 - val_loss: 0.1760 - val_accuracy: 0.9530\n",
            "Epoch 199/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3134 - accuracy: 0.8967\n",
            "Epoch 00199: val_accuracy did not improve from 0.95375\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3134 - accuracy: 0.8968 - val_loss: 0.1796 - val_accuracy: 0.9521\n",
            "Epoch 200/200\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.3062 - accuracy: 0.9009\n",
            "Epoch 00200: val_accuracy improved from 0.95375 to 0.95385, saving model to svhn_v1.h5\n",
            "1200/1200 [==============================] - 30s 25ms/step - loss: 0.3062 - accuracy: 0.9010 - val_loss: 0.1763 - val_accuracy: 0.9538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f16abbfa7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPqRhB754XoC"
      },
      "source": [
        "## Fit and evaluate the model. Print the loss and accuracy for the test data (10 points)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_RgjLjWprLF",
        "outputId": "28a2f33a-6738-4dcb-f662-5c8b0e95e9fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(testX,testY,verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "563/563 [==============================] - 3s 5ms/step - loss: 0.3863 - accuracy: 0.8916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38626253604888916, 0.8916110992431641]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cdRWtkunUqu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}